{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL7Wg-vUmo4s"
      },
      "source": [
        "# Data pre-processing tool kit for deep-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEMx4dfzuSEX"
      },
      "source": [
        "## For cnn binary and multiclass classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsCRA4NTnyxp"
      },
      "source": [
        "### to get total path(classes/folders) in directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMs1IihOnyBl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Walk through 10_food_classes directory and list number of files - just change directory in os.walk()\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmnNhuLEpohK"
      },
      "source": [
        "### directory paths for train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VorchGAlpnGD"
      },
      "outputs": [],
      "source": [
        "train_dir = \"10_food_classes_all_data/train/\"\n",
        "test_dir = \"10_food_classes_all_data/test/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys8t31BSpc9h"
      },
      "source": [
        "### get toal classes in avriable in sorted order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jgWsZGQpixN"
      },
      "outputs": [],
      "source": [
        "# Get the class names for our multi-class dataset\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyABzBksnopk"
      },
      "source": [
        "### to plot random image form directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5K9LGs1nPto"
      },
      "outputs": [],
      "source": [
        "# View an image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "  # Setup target directory (we'll view images from here)\n",
        "  target_folder = target_dir+target_class\n",
        "\n",
        "  # Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "\n",
        "  # Read in the image and plot it using matplotlib\n",
        "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\");\n",
        "\n",
        "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrPX05AuoTLh"
      },
      "source": [
        "### image augmentation and creating train and test set\n",
        "\n",
        "> ðŸ¤” **Question:** Should I use data augmentation? And how much should I augment?\n",
        "\n",
        "Data augmentation is a way to try and prevent a model overfitting. If your model is overfiting (e.g. the validation loss keeps increasing), you may want to try using data augmentation.\n",
        "\n",
        "As for how much to data augment, there's no set practice for this. Best to check out the options in the `ImageDataGenerator` class and think about how a model in your use case might benefit from some data augmentation.\n",
        "\n",
        "Now we've got augmented data, let's try and refit a model on it and see how it affects training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlNlKzvfnPlJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create ImageDataGenerator training instance with data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=20, # rotate the image slightly between 0 and 20 degrees (note: this is an int not a float)\n",
        "                                             shear_range=0.2, # shear the image\n",
        "                                             zoom_range=0.2, # zoom into the image\n",
        "                                            #  width_shift_range=0.2, # shift the image width ways\n",
        "                                            #  height_shift_range=0.2, # shift the image height ways\n",
        "                                             horizontal_flip=True) # flip the image on the horizontal axis\n",
        "\n",
        "\n",
        "# Create ImageDataGenerator test instance without data augmentation\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical') # changed to categorical in case binary calssification use ***class_mode=\"binary\",\n",
        "\n",
        "test_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn3GSMVCuALz"
      },
      "source": [
        "#### Update in tensorflow\n",
        "\n",
        "below you can see we have used ImageDataGenerator which has been updated to image_dataset_from_directory of tf.keras.utils.\n",
        "\n",
        "The main differences between them are:\n",
        "\n",
        "*   rescaling & data loading:\n",
        "    \n",
        "\n",
        "  1.   In `ImageDataGenerator` we rescaled imag then applied flow_from_directory, we used **target_size** and **class_mode**\n",
        "  2.   In `image_dataset_from_directory` we got the data from directory using **image_size** and **label_mode** which are used same as *target_size* and *class_mode*. here, to rescale image we have added new layer in Sequential Model:\n",
        "\n",
        "```\n",
        "tf.keras.layers.Rescaling(1./255,input_shape=(224,224,3)),\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLYjYZScnAc0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "# set a path from our current directories\n",
        "train_dir = \"pizza_steak/train/\"\n",
        "test_dir = \"pizza_steak/test/\"\n",
        "\n",
        "train_data = image_dataset_from_directory(directory=train_dir,\n",
        "                                               batch_size=32,\n",
        "                                               image_size = (224,224),\n",
        "                                               label_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = image_dataset_from_directory(directory=test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               image_size = (224,224),\n",
        "                                               label_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "# build cnn model\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "\n",
        "    tf.keras.layers.Rescaling(1./255,input_shape=(224,224,3)),\n",
        "    tf.keras.layers.Conv2D(filters=10, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, padding=\"valid\"),\n",
        "    tf.keras.layers.Conv2D(10,3, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(10,3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# label and data created for us using flow_from_directory\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data), # total img / batch_size = total steps for machine to know and memory calculation for storing\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZGZj1cuqqSJ"
      },
      "source": [
        "### Takes image name(/path) as inout and predict image class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q8Q5_q_md1_"
      },
      "outputs": [],
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224):\n",
        "  \"\"\"\n",
        "  Reads an image from filename, turns it into a tensor\n",
        "  and reshapes it to (img_shape, img_shape, colour_channel).\n",
        "  \"\"\"\n",
        "  # Read in target file (an image)\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the read file into a tensor & ensure 3 colour channels\n",
        "  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "\n",
        "  # Resize the image (to the same size our model was trained on)\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255.\n",
        "  return img\n",
        "\n",
        "\n",
        "# Adjust function to work with multi-class\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n",
        "\n",
        "\n",
        "pred_and_plot(mdoel, \"xyz.jpeg\", class_names). # here class name we got alredy as above using pathlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diygLD2Ergm3"
      },
      "source": [
        "### sequential model example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXtkJxJdrkNn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "# Create our model (a clone of model_8, except to be multi-class)\n",
        "model_9 = Sequential([\n",
        "  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax') # changed to have 10 neurons (same as number of classes) and 'softmax' activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_9.compile(loss=\"categorical_crossentropy\", # changed to categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_9 = model_9.fit(train_data, # now 10 different classes\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ1b5ycurOyj"
      },
      "source": [
        "### save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klDO5qBvnQUb"
      },
      "outputs": [],
      "source": [
        "model_11.save(\"saved_trained_model\") # or\n",
        "model_11.save(\"saved_trained_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzuLWKVjqQrz"
      },
      "source": [
        "### to evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBXipU6XnQSN"
      },
      "outputs": [],
      "source": [
        "model_9.evaluate(test_data), model_9.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYVT3iLCnROq"
      },
      "source": [
        "### To plot History curves for both training and validation set\n",
        "\n",
        ">Note: this function only helpful when we are using metrics = [\"accuracy\"], we might have to change function for different accuracy metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgiofxw2nQPs"
      },
      "outputs": [],
      "source": [
        "# Plot the validation and training data separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UUE-96SsV1z"
      },
      "source": [
        "### prevent our model overfitting. A couple of ways to prevent overfitting include:\n",
        "\n",
        "- **Get more data** - Having more data gives the model more opportunities to learn patterns, patterns which may be more generalizable to new examples.\n",
        "- **Simplify model** - If the current model is already overfitting the training data, it may be too complicated of a model. This means it's learning the patterns of the data too well and isn't able to generalize well to unseen data. One way to simplify a model is to reduce the number of layers it uses or to reduce the number of hidden units in each layer.\n",
        "- **Use data augmentation** - Data augmentation manipulates the training data in a way so that's harder for the model to learn as it artificially adds more variety to the data. If a model is able to learn patterns in augmented data, the model may be able to generalize better to unseen data.\n",
        "- **Use transfer learning** - Transfer learning involves leverages the patterns (also called pretrained weights) one model has learned to use as the foundation for your own task. In our case, we could use one computer vision model pretrained on a large variety of images and then tweak it slightly to be more specialized for food images.\n",
        "\n",
        "> ðŸ”‘ **Note:** Preventing overfitting is also referred to as **regularization**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preprocessing for Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create model function\n",
        "\n",
        "This function take transfer learning url from tensorflow_Hub as model_url and num_classes which is output nodes and returns feature extraction model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "\n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in output layer,\n",
        "      should be equal to number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature\n",
        "    extractor layer and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False, # freeze the underlying patterns\n",
        "                                           name='feature_extraction_layer',\n",
        "                                           input_shape=IMAGE_SHAPE+(3,)) # define the input image shape\n",
        "\n",
        "  # Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "    feature_extractor_layer, # use the feature extraction layer as the base\n",
        "    layers.Dense(num_classes, activation='softmax', name='output_layer') # create our own output layer\n",
        "  ])\n",
        "\n",
        "  return model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
